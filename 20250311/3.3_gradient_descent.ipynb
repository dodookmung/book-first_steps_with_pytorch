{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 파이토치에서의 경사하강법\n",
    "\n",
    "파이토치에서는 기본 단위로 텐서(tensor)라는 것을 사용합니다. </br>\n",
    "텐서는 다차원 배열(array)이라고 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이토치 설치\n",
    "\n",
    "```bash\n",
    "!pip3 install torch torchvision torchaudio\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.Tensor(2,3)\n",
    "# 이 때 텐서의 모양(shape)은 2 X 3입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad는 해당 텐서에 대한 기울기를 저장할지의 여부\n",
    "x_tensor = torch.tensor(data=[2.0, 3.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 12.]) None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/_9m82vt913l986ymhxzkh3280000gn/T/ipykernel_64607/684665758.py:11: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  print(x.grad, y.grad, z.grad)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(data=[2.0, 3.0], requires_grad=True)\n",
    "y = x**2\n",
    "z = 2*y + 3\n",
    "\n",
    "target = torch.tensor([3.0, 4.0])\n",
    "loss = torch.sum(torch.abs(z-target))\n",
    "loss.backward()\n",
    "\n",
    "print(x.grad, y.grad, z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.grad는 기울기가 계산되지만,  y.grad, z.grad는 잎 노드가 아니기 때문에\n",
    "결괏값이 None으로 리턴된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn         # 신경망 모델들이 포함\n",
    "import torch.optim as optim   # 경사 하강법 알고리즘\n",
    "import torch.nn.init as init  # 텐서에 초기값을 주기 위한 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 500\n",
    "\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10,10)   # 해당 텐서의 값들을 -10~10까지의 숫자로 균등하게 초기화, 결과적으로 x에는 -10~10까지의 숫자들이 무작위로 들어감\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)  # y와 같은 모양을 가지는 텐서를 만들어야 하기에 init.normal()로 초기화\n",
    "y = 2*x+3\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)\n",
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.4619)\n",
      "-0.6874117255210876 -0.5664626955986023\n",
      "tensor(11.2095)\n",
      "-0.2135041058063507 -0.5551027655601501\n",
      "tensor(9.0234)\n",
      "0.25328710675239563 -0.539782702922821\n",
      "tensor(6.9455)\n",
      "0.7072342038154602 -0.5186827778816223\n",
      "tensor(5.1168)\n",
      "1.13021719455719 -0.486882746219635\n",
      "tensor(3.8348)\n",
      "1.474005103111267 -0.43786272406578064\n",
      "tensor(3.3907)\n",
      "1.6523884534835815 -0.36410272121429443\n",
      "tensor(3.2699)\n",
      "1.70968759059906 -0.2749226987361908\n",
      "tensor(3.1745)\n",
      "1.7396953105926514 -0.18226267397403717\n",
      "tensor(3.0819)\n",
      "1.7603853940963745 -0.08838267624378204\n",
      "tensor(2.9898)\n",
      "1.7794545888900757 0.005697324872016907\n",
      "tensor(2.8982)\n",
      "1.7938024997711182 0.10025732964277267\n",
      "tensor(2.8069)\n",
      "1.80712890625 0.19485734403133392\n",
      "tensor(2.7157)\n",
      "1.8204553127288818 0.2894573509693146\n",
      "tensor(2.6245)\n",
      "1.833162784576416 0.3840973675251007\n",
      "tensor(2.5335)\n",
      "1.848388671875 0.47823745012283325\n",
      "tensor(2.4427)\n",
      "1.8650487661361694 0.572037398815155\n",
      "tensor(2.3524)\n",
      "1.8801947832107544 0.6658574342727661\n",
      "tensor(2.2624)\n",
      "1.893624186515808 0.7597373723983765\n",
      "tensor(2.1726)\n",
      "1.9079939126968384 0.8533774614334106\n",
      "tensor(2.0831)\n",
      "1.9228650331497192 0.9467975497245789\n",
      "tensor(1.9946)\n",
      "1.9362354278564453 1.0398175716400146\n",
      "tensor(1.9089)\n",
      "1.9454338550567627 1.1318373680114746\n",
      "tensor(1.8240)\n",
      "1.9545199871063232 1.2235172986984253\n",
      "tensor(1.7400)\n",
      "1.9651497602462769 1.3145173788070679\n",
      "tensor(1.6577)\n",
      "1.9746367931365967 1.404577374458313\n",
      "tensor(1.5788)\n",
      "1.9810558557510376 1.4930773973464966\n",
      "tensor(1.5035)\n",
      "1.9835532903671265 1.5796172618865967\n",
      "tensor(1.4325)\n",
      "1.984015941619873 1.6636574268341064\n",
      "tensor(1.3663)\n",
      "1.983590006828308 1.7447574138641357\n",
      "tensor(1.3046)\n",
      "1.9854665994644165 1.8230574131011963\n",
      "tensor(1.2475)\n",
      "1.9861466884613037 1.898337483406067\n",
      "tensor(1.1955)\n",
      "1.988104224205017 1.9702177047729492\n",
      "tensor(1.1470)\n",
      "1.9887031316757202 2.0395376682281494\n",
      "tensor(1.1035)\n",
      "1.989808201789856 2.1052374839782715\n",
      "tensor(1.0640)\n",
      "1.9896314144134521 2.1678974628448486\n",
      "tensor(1.0288)\n",
      "1.9858075380325317 2.2267775535583496\n",
      "tensor(0.9974)\n",
      "1.9847427606582642 2.2824573516845703\n",
      "tensor(0.9702)\n",
      "1.9869779348373413 2.334277391433716\n",
      "tensor(0.9468)\n",
      "1.98884916305542 2.3822972774505615\n",
      "tensor(0.9263)\n",
      "1.990816593170166 2.4272167682647705\n",
      "tensor(0.9091)\n",
      "1.9902986288070679 2.468337059020996\n",
      "tensor(0.8947)\n",
      "1.9919438362121582 2.506016969680786\n",
      "tensor(0.8824)\n",
      "1.9903613328933716 2.540956735610962\n",
      "tensor(0.8716)\n",
      "1.991077184677124 2.573556661605835\n",
      "tensor(0.8621)\n",
      "1.9925155639648438 2.604316473007202\n",
      "tensor(0.8536)\n",
      "1.9919497966766357 2.633216619491577\n",
      "tensor(0.8463)\n",
      "1.9922996759414673 2.659996747970581\n",
      "tensor(0.8402)\n",
      "1.99232816696167 2.6844370365142822\n",
      "tensor(0.8354)\n",
      "1.9921705722808838 2.7061169147491455\n"
     ]
    }
   ],
   "source": [
    "label = y_noise\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad()   # 각 반복시 기울기를 0으로 초기화\n",
    "    output = model(x)       # 모델에 x를 전달하고 결과를 output에 저장   (순전파)\n",
    "\n",
    "    loss = loss_func(output, label)  # 손실 함수의 정의에 따른 output과 y_noise의 차이를 loss에 저장\n",
    "    loss.backward()    # 각 변수, 즉 w, b에 대한 기울기가 계산됨    \n",
    "    optimizer.step()   # 파라미터로 들어갔던 model.parameters()에서 리턴되는 변수들의 기울기에 학습률 0.01을 곱하여 빼줌으로써 업데이트.  (역전파)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "        param_list = list(model.parameters())\n",
    "        print(param_list[0].item(), param_list[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
